#!/bin/bash

# How many times should I get the webpage?
pagecount=200

scratchfile=/tmp/scratch.$$

# Collect the web pages, strip the line with hostname ...
for i in `seq 1 $pagecount`;
do
   curl -s http://127.0.0.1:31806/cgi-bin/hello.cgi | grep host >> $scratchfile

   # Show some progress to user
   if ! (( $i % 25 )); then
    echo "$i pages pulled, so far ..." 
   fi
done

# How many pages came from each host?
sort $scratchfile | uniq -c
rm $scratchfile

